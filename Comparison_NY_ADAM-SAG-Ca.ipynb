{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pickup_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'trip_duration']\n",
      "(1458644, 6)\n",
      "pickup_longitude          float64\n",
      "pickup_latitude           float64\n",
      "dropoff_longitude         float64\n",
      "dropoff_latitude          float64\n",
      "trip_duration               int64\n",
      "pickup_mins_of_the_day      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Please, to run the experiments donwload the following dataset and put them in the /Dataset folder:\n",
    "#     - NY_train.csv - \n",
    "#       https://www.kaggle.com/c/nyc-taxi-trip-duration/data?select=train.zip\n",
    "#       (extract the .csv file and rename it to NY_train.csv)\n",
    "\n",
    "filename = \"Datasets/NY_train.csv\"\n",
    "df = pd.read_csv(filename, header=0, usecols=[2,5,6,7,8,10])\n",
    "df = df.dropna()\n",
    "\n",
    "print(list(df.columns.values))\n",
    "\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'] , errors='coerce')\n",
    "df['hour'] = df.pickup_datetime.dt.hour\n",
    "df['minute'] = df.pickup_datetime.dt.minute\n",
    "df['pickup_mins_of_the_day'] = df['hour']*60 + df['minute']\n",
    "df = df.drop(['pickup_datetime', 'hour','minute'], axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458644, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[['pickup_mins_of_the_day','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']]\n",
    "x = x.to_numpy()\n",
    "y = df['trip_duration']\n",
    "y = y.to_numpy()\n",
    "\n",
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458644, 5)\n",
      "(1458644, 155)\n"
     ]
    }
   ],
   "source": [
    "import CaGD_ls\n",
    "\n",
    "x = np.ascontiguousarray(x)\n",
    "print(x.shape)\n",
    "x = CaGD_ls.tens_pow(x,3) \n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x_scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458644, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.999, svd_solver='full')\n",
    "pca.fit(x_scaled)\n",
    "x_scaled_pca = pca.transform(x_scaled)\n",
    "print(np.shape(x_scaled_pca))\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled_pca = CaGD_ls.add_bias(x_scaled_pca)\n",
    "print(np.shape(x_scaled_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(y.std())\n",
    "print(len(y))\n",
    "sns.distplot(y, hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4})\n",
    "plt.show()\n",
    "\n",
    "idx = y<=10000\n",
    "sns.distplot(y[idx], hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 2})\n",
    "\n",
    "plt.show()\n",
    "print(y[idx].std())\n",
    "print(len(y[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled_pca = x_scaled_pca[idx]\n",
    "y = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "block_dim = 2\n",
    "loss_accepted = 1e-5\n",
    "max_iter = 5e1\n",
    "lambda_LASSO = 1e-2\n",
    "batch_size = 256\n",
    "\n",
    "n = np.shape(x_scaled_pca)[1]\n",
    "print(\"number of parameters \", n)\n",
    "print(\"number of points \", x_scaled_pca.shape[0])\n",
    "theta_0 = np.random.uniform(-1/n**0.5,1/n**0.5,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_momCA_GS,iteration_momCA_GS,theta_momCA_GS,t_momCA_GS = CaGD_ls.mom_CA_BCD_GS_ls(\n",
    "                            x_scaled_pca,y,theta_0,lambda_LASSO,lr,loss_accepted,max_iter,2,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_momCA_random,iteration_momCA_random,theta_momCA_random,t_momCA_random = CaGD_ls.mom_CA_BCD_random_ls(\n",
    "                            x_scaled_pca,y,theta_0,lambda_LASSO,lr,loss_accepted,max_iter,2,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_CABCD_stand_GS,iteration_CABCD_stand_GS,theta_CABCD_stand_GS,t_CABCD_stand_GS = CaGD_ls.CA_BCD_GS_ls(\n",
    "                             x_scaled_pca,y,theta_0,lambda_LASSO,lr,loss_accepted,max_iter,2,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_ADAM,iteration_ADAM,theta_ADAM,t_ADAM = CaGD_ls.ADAM_ls(x_scaled_pca,y,theta_0,lambda_LASSO,batch_size,lr,loss_accepted,max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-6\n",
    "loss_SAG,iteration_SAG,theta_SAG,t_SAG = CaGD_ls.SAG_ls(x_scaled_pca,y,theta_0,lambda_LASSO,batch_size,lr,loss_accepted,max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss min mom GS CA = \", min(loss_momCA_GS))\n",
    "print(\"loss min mom random CA = \", min(loss_momCA_random))\n",
    "print(\"loss min standard GS CA = \", min(loss_CABCD_stand_GS))\n",
    "print(\"loss min ADAM = \", min(loss_ADAM))\n",
    "print(\"loss min SAG = \", min(loss_SAG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(t_momCA_GS, loss_momCA_GS, label=\"CaBCD mom GS\")\n",
    "plt.plot(t_momCA_random, loss_momCA_random, label=\"CaBCD mom random\")\n",
    "plt.plot(t_CABCD_stand_GS, loss_CABCD_stand_GS, label=\"CaBCD GS\")\n",
    "plt.plot(t_ADAM, loss_ADAM, label=\"ADAM\")\n",
    "plt.plot(t_SAG, loss_SAG, label=\"SAG\")\n",
    "plt.legend()\n",
    "plt.title('Loss MSE vs time NY')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlim([0,10])\n",
    "plt.ylim([min(loss_ADAM)*0.5,max(loss_ADAM)])\n",
    "# plt.savefig('CaBCD_vs_all_time_NY.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(iteration_momCA_GS, loss_momCA_GS, label=\"CaBCD mom GS\")\n",
    "plt.plot(iteration_momCA_random, loss_momCA_random, label=\"CaBCD mom random\")\n",
    "plt.plot(iteration_CABCD_stand_GS, loss_CABCD_stand_GS, label=\"CaBCD GS\")\n",
    "plt.plot(iteration_ADAM, loss_ADAM, label=\"ADAM\")\n",
    "plt.plot(iteration_SAG, loss_SAG, label=\"SAG\")\n",
    "plt.legend()\n",
    "plt.title('Loss MSE vs iteration NY')\n",
    "plt.xlabel('iteration (over the entire dataset)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlim([0,30])\n",
    "plt.ylim([min(loss_ADAM)*0.5,max(loss_ADAM)])\n",
    "# plt.savefig('CaBCD_vs_all_iteration_NY.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
